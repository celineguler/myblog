---
layout: post
title: "Black Holes' High Entropy"
---

Just want to point out that I realized my misconceptions about entropy and chaos while trying to ask a simple question about the chaoticity of a system and its limits. What became clear was that when we wanted to question how complex a physical system could be, it is silly to ask about the most chaotic thing in the universe; cause apparently black holes aren't considered "chaotic".

Let me clarify the concepts the best I can with giving some definitions.

Here's *entropy* by [Quora][Quora]:
{: .italic-gray.indented}
> *"Entropy is the measure of energy dispersion. The more entropy, the more equally the energy is distributed."*

Here's *chaos* by [Quora][Quora]:
{: .italic-gray.indented}
> *"Chaos is a system that exhibits complex dynamics, which is sensitive to initial conditions. Chaotic behavior has a certain order. "*

Here's *entropy* by Google:
{: .italic-gray.indented}
> *"A thermodynamic quantity representing the unavailability of a system's thermal energy for conversion into mechanical work, often interpreted as the degree of disorder or randomness in the system."*

Here's *chaos* by Google:
{: .italic-gray.indented}
> *"The property of a complex system whose behaviour is so unpredictable as to appear random, owing to great sensitivity to small changes in conditions."*

Quora highly disagrees that chaos and entropy are not interchangeable. Frankly, I made a generalization because most writers use "on the other hand", "whereas". Google's definitions mostly allign with (I trust Quora more than Google) so we can also say Google agreed the statement. But I don't think this tweet wouldn't agree that Google sorting both terms in the cast of Physics.
<br>
_____________________________________________________________________________________________________________

<br>

You can check [this][chatgpt], my full interview where I poorly try to explore the concepts of *chaos* and *entropy*.	I must mention that the interview ends without satisfiying my question about the *limit for complexity in physical world*. Because this concept, physical complexity, feel inadequate when you think of systems such as the brain or cloud (not complex enough), while complexities such as black holes or space that never fit into a circle while enlarging its diameter make it feel neutral and simplified, actually *not complex* beside math.

As we get to the theory, we can meausure and talk about complexity with the parameters such as amount of components, we do our math as infinite amount of components will give infinite complexity! 

Here are the main criterias:

__Number of Components__: A system with more components (e.g., neurons, particles, elements) can be considered more complex, but this metric doesn't account for interactions and emergent properties.

__Interactions and Connectivity__: The number and nature of interactions among components contribute to complexity. Networks with intricate connections can be more complex.

__Information Theory__: Complexity can be related to the amount of information needed to describe a system's behavior. High information content suggests higher complexity.

__Emergent Properties__: Systems that exhibit emergent behaviors, where collective interactions lead to novel phenomena, are often considered more complex.

__Adaptability__: Systems that can adapt to changing environments or evolve over time tend to be more complex.

__Hierarchy and Self-Organization__: Systems with hierarchical organization and self-organizing properties can be considered more complex due to multiple levels of interactions.


[Quora]: https://www.quora.com/What-is-the-difference-between-entropy-and-chaos
[chatgpt]: https://chat.openai.com/share/5447bd97-3859-4a34-afbd-04f514c741be